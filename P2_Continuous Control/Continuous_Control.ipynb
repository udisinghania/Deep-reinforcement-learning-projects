{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Watch for changes in any of the imported files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "#env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.14699999671429395\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note: `brain_name` should be defined globally\n",
    "def env_step(env, actions):\n",
    "    # Execute the action for each agent in the environment\n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    # Get the next state for each agent\n",
    "    next_states = env_info.vector_observations\n",
    "    # Get the reward for each agent\n",
    "    rewards = env_info.rewards\n",
    "    # Get whether or not the episode has terminated\n",
    "    dones = env_info.local_done\n",
    "    return next_states, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ddpg(agent, n_episodes=1000, max_t=1000, save_file=None):\n",
    "    \"\"\"Deep Deterministic Policy Gradients.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        agent (Agent): an instance of a DDPG agent(s)\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of time steps per episode\n",
    "        save_file (string): prefix for the actor and critic model filenames\n",
    "    \"\"\"\n",
    "    \n",
    "    # All the scores from each episode\n",
    "    scores_all = []\n",
    "    # The last 100 scores\n",
    "    scores_window = deque(maxlen=100)\n",
    "    \n",
    "    # Loop over each episode\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        # Reset the environment\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        # Get the current state for each agent\n",
    "        states = env_info.vector_observations\n",
    "        # Reset the noise\n",
    "        agent.reset()\n",
    "        # Initialize the score for each agent\n",
    "        scores = np.zeros(num_agents)\n",
    "        \n",
    "        # Loop over each time step\n",
    "        for t in range(max_t):            \n",
    "            # Select an action for each agent according to the current policy\n",
    "            actions = agent.act(states)\n",
    "            # Execute the actions in the environment,\n",
    "            #     then observe the next state and reward for each agent\n",
    "            next_states, rewards, dones = env_step(env, actions)\n",
    "            # Learn from experience and update network parameters for each agent\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            \n",
    "            # Update the score for each agent\n",
    "            scores += rewards\n",
    "            # Roll over each state to the next time step\n",
    "            states = next_states\n",
    "            # Record the current mean score across all agents, (overwriting the output)\n",
    "            print(f'\\rEpisode {i_episode}\\tTimestep {t}'\n",
    "                  f'\\tCurrent Score: {np.mean(scores):.2f}', end=\"\")\n",
    "            # Exit the loop if the episode has terminated\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        \n",
    "        # Take the average score across all agents\n",
    "        score = np.mean(scores)\n",
    "        # Save the most recent score\n",
    "        scores_all.append(score)\n",
    "        scores_window.append(score)\n",
    "        # Record the mean score over the last 100 scores\n",
    "        mean_score = np.mean(scores_window)\n",
    "                \n",
    "        # Per episode, record the mean score over the last 100 (or less) episodes\n",
    "        print(f'\\rEpisode {i_episode}'\n",
    "              f'\\tAverage score over the last 100 episodes: {mean_score:.2f}')\n",
    "            \n",
    "        # Goal: Reach 30+ over 100 consecutive episodes\n",
    "        if mean_score >= 30.0:\n",
    "            print(f'\\nEnvironment solved in {i_episode:d} episodes!'\n",
    "                  f'\\tAverage score over the last 100 episodes: {mean_score:.2f}')\n",
    "            if save_file:\n",
    "                torch.save(agent.actor_local.state_dict(), f'{save_file}_actor.pth')\n",
    "                torch.save(agent.critic_local.state_dict(), f'{save_file}_critic.pth')\n",
    "            break\n",
    "            \n",
    "    return scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage score over the last 100 episodes: 0.36\n",
      "Episode 2\tAverage score over the last 100 episodes: 0.24\n",
      "Episode 3\tAverage score over the last 100 episodes: 0.17\n",
      "Episode 4\tAverage score over the last 100 episodes: 0.13\n",
      "Episode 5\tAverage score over the last 100 episodes: 0.11\n",
      "Episode 6\tAverage score over the last 100 episodes: 0.23\n",
      "Episode 7\tAverage score over the last 100 episodes: 0.33\n",
      "Episode 8\tAverage score over the last 100 episodes: 0.39\n",
      "Episode 9\tAverage score over the last 100 episodes: 0.46\n",
      "Episode 10\tAverage score over the last 100 episodes: 0.54\n",
      "Episode 11\tAverage score over the last 100 episodes: 0.58\n",
      "Episode 12\tAverage score over the last 100 episodes: 0.61\n",
      "Episode 13\tAverage score over the last 100 episodes: 0.63\n",
      "Episode 14\tAverage score over the last 100 episodes: 0.64\n",
      "Episode 15\tAverage score over the last 100 episodes: 0.66\n",
      "Episode 16\tAverage score over the last 100 episodes: 0.69\n",
      "Episode 17\tAverage score over the last 100 episodes: 0.72\n",
      "Episode 18\tAverage score over the last 100 episodes: 0.77\n",
      "Episode 19\tAverage score over the last 100 episodes: 0.81\n",
      "Episode 20\tAverage score over the last 100 episodes: 0.87\n",
      "Episode 21\tAverage score over the last 100 episodes: 0.94\n",
      "Episode 22\tAverage score over the last 100 episodes: 1.01\n",
      "Episode 23\tAverage score over the last 100 episodes: 1.10\n",
      "Episode 24\tAverage score over the last 100 episodes: 1.21\n",
      "Episode 25\tAverage score over the last 100 episodes: 1.33\n",
      "Episode 26\tAverage score over the last 100 episodes: 1.46\n",
      "Episode 27\tAverage score over the last 100 episodes: 1.58\n",
      "Episode 28\tAverage score over the last 100 episodes: 1.74\n",
      "Episode 29\tAverage score over the last 100 episodes: 1.87\n",
      "Episode 30\tAverage score over the last 100 episodes: 2.02\n",
      "Episode 31\tAverage score over the last 100 episodes: 2.24\n",
      "Episode 32\tAverage score over the last 100 episodes: 2.46\n",
      "Episode 33\tAverage score over the last 100 episodes: 2.69\n",
      "Episode 34\tAverage score over the last 100 episodes: 2.94\n",
      "Episode 35\tAverage score over the last 100 episodes: 3.16\n",
      "Episode 36\tAverage score over the last 100 episodes: 3.39\n",
      "Episode 37\tAverage score over the last 100 episodes: 3.65\n",
      "Episode 38\tAverage score over the last 100 episodes: 3.90\n",
      "Episode 39\tAverage score over the last 100 episodes: 4.12\n",
      "Episode 40\tAverage score over the last 100 episodes: 4.33\n",
      "Episode 41\tAverage score over the last 100 episodes: 4.56\n",
      "Episode 42\tAverage score over the last 100 episodes: 4.82\n",
      "Episode 43\tAverage score over the last 100 episodes: 5.05\n",
      "Episode 44\tAverage score over the last 100 episodes: 5.26\n",
      "Episode 45\tAverage score over the last 100 episodes: 5.47\n",
      "Episode 46\tAverage score over the last 100 episodes: 5.70\n",
      "Episode 47\tAverage score over the last 100 episodes: 5.96\n",
      "Episode 48\tAverage score over the last 100 episodes: 6.20\n",
      "Episode 49\tAverage score over the last 100 episodes: 6.45\n",
      "Episode 50\tAverage score over the last 100 episodes: 6.72\n",
      "Episode 51\tAverage score over the last 100 episodes: 6.94\n",
      "Episode 52\tAverage score over the last 100 episodes: 7.21\n",
      "Episode 53\tAverage score over the last 100 episodes: 7.49\n",
      "Episode 54\tAverage score over the last 100 episodes: 7.73\n",
      "Episode 55\tAverage score over the last 100 episodes: 7.97\n",
      "Episode 56\tAverage score over the last 100 episodes: 8.25\n",
      "Episode 57\tAverage score over the last 100 episodes: 8.47\n",
      "Episode 58\tAverage score over the last 100 episodes: 8.73\n",
      "Episode 59\tAverage score over the last 100 episodes: 8.96\n",
      "Episode 60\tAverage score over the last 100 episodes: 9.21\n",
      "Episode 61\tAverage score over the last 100 episodes: 9.47\n",
      "Episode 62\tAverage score over the last 100 episodes: 9.72\n",
      "Episode 63\tAverage score over the last 100 episodes: 9.96\n",
      "Episode 64\tAverage score over the last 100 episodes: 10.18\n",
      "Episode 65\tAverage score over the last 100 episodes: 10.39\n",
      "Episode 66\tAverage score over the last 100 episodes: 10.63\n",
      "Episode 67\tAverage score over the last 100 episodes: 10.83\n",
      "Episode 68\tAverage score over the last 100 episodes: 11.06\n",
      "Episode 69\tAverage score over the last 100 episodes: 11.29\n",
      "Episode 70\tAverage score over the last 100 episodes: 11.49\n",
      "Episode 71\tAverage score over the last 100 episodes: 11.73\n",
      "Episode 72\tAverage score over the last 100 episodes: 11.92\n",
      "Episode 73\tAverage score over the last 100 episodes: 12.08\n",
      "Episode 74\tAverage score over the last 100 episodes: 12.28\n",
      "Episode 75\tAverage score over the last 100 episodes: 12.47\n",
      "Episode 76\tAverage score over the last 100 episodes: 12.62\n",
      "Episode 77\tAverage score over the last 100 episodes: 12.79\n",
      "Episode 78\tAverage score over the last 100 episodes: 12.97\n",
      "Episode 79\tAverage score over the last 100 episodes: 13.13\n",
      "Episode 80\tAverage score over the last 100 episodes: 13.29\n",
      "Episode 81\tAverage score over the last 100 episodes: 13.45\n",
      "Episode 82\tAverage score over the last 100 episodes: 13.61\n",
      "Episode 83\tAverage score over the last 100 episodes: 13.78\n",
      "Episode 84\tAverage score over the last 100 episodes: 13.96\n",
      "Episode 85\tAverage score over the last 100 episodes: 14.12\n",
      "Episode 86\tAverage score over the last 100 episodes: 14.31\n",
      "Episode 87\tAverage score over the last 100 episodes: 14.49\n",
      "Episode 88\tAverage score over the last 100 episodes: 14.66\n",
      "Episode 89\tAverage score over the last 100 episodes: 14.83\n",
      "Episode 90\tAverage score over the last 100 episodes: 15.02\n",
      "Episode 91\tAverage score over the last 100 episodes: 15.20\n",
      "Episode 92\tAverage score over the last 100 episodes: 15.38\n",
      "Episode 93\tAverage score over the last 100 episodes: 15.56\n",
      "Episode 94\tAverage score over the last 100 episodes: 15.75\n",
      "Episode 95\tAverage score over the last 100 episodes: 15.93\n",
      "Episode 96\tAverage score over the last 100 episodes: 16.10\n",
      "Episode 97\tAverage score over the last 100 episodes: 16.26\n",
      "Episode 98\tAverage score over the last 100 episodes: 16.44\n",
      "Episode 99\tAverage score over the last 100 episodes: 16.63\n",
      "Episode 100\tAverage score over the last 100 episodes: 16.82\n",
      "Episode 101\tAverage score over the last 100 episodes: 17.16\n",
      "Episode 102\tAverage score over the last 100 episodes: 17.51\n",
      "Episode 103\tAverage score over the last 100 episodes: 17.87\n",
      "Episode 104\tAverage score over the last 100 episodes: 18.24\n",
      "Episode 105\tAverage score over the last 100 episodes: 18.61\n",
      "Episode 106\tAverage score over the last 100 episodes: 18.98\n",
      "Episode 107\tAverage score over the last 100 episodes: 19.33\n",
      "Episode 108\tAverage score over the last 100 episodes: 19.70\n",
      "Episode 109\tAverage score over the last 100 episodes: 20.06\n",
      "Episode 110\tAverage score over the last 100 episodes: 20.41\n",
      "Episode 111\tAverage score over the last 100 episodes: 20.78\n",
      "Episode 112\tAverage score over the last 100 episodes: 21.14\n",
      "Episode 113\tAverage score over the last 100 episodes: 21.51\n",
      "Episode 114\tAverage score over the last 100 episodes: 21.86\n",
      "Episode 115\tAverage score over the last 100 episodes: 22.22\n",
      "Episode 116\tAverage score over the last 100 episodes: 22.57\n",
      "Episode 117\tAverage score over the last 100 episodes: 22.94\n",
      "Episode 118\tAverage score over the last 100 episodes: 23.30\n",
      "Episode 119\tAverage score over the last 100 episodes: 23.66\n",
      "Episode 120\tAverage score over the last 100 episodes: 24.01\n",
      "Episode 121\tAverage score over the last 100 episodes: 24.36\n",
      "Episode 122\tAverage score over the last 100 episodes: 24.72\n",
      "Episode 123\tAverage score over the last 100 episodes: 25.06\n",
      "Episode 124\tAverage score over the last 100 episodes: 25.39\n",
      "Episode 125\tAverage score over the last 100 episodes: 25.45\n",
      "Episode 126\tAverage score over the last 100 episodes: 25.43\n",
      "Episode 127\tAverage score over the last 100 episodes: 25.44\n",
      "Episode 128\tAverage score over the last 100 episodes: 25.45\n",
      "Episode 129\tAverage score over the last 100 episodes: 25.52\n",
      "Episode 130\tAverage score over the last 100 episodes: 25.62\n",
      "Episode 131\tAverage score over the last 100 episodes: 25.79\n",
      "Episode 132\tAverage score over the last 100 episodes: 25.95\n",
      "Episode 133\tAverage score over the last 100 episodes: 26.17\n",
      "Episode 134\tAverage score over the last 100 episodes: 26.39\n",
      "Episode 135\tAverage score over the last 100 episodes: 26.59\n",
      "Episode 136\tAverage score over the last 100 episodes: 26.85\n",
      "Episode 137\tAverage score over the last 100 episodes: 27.08\n",
      "Episode 138\tAverage score over the last 100 episodes: 27.32\n",
      "Episode 139\tAverage score over the last 100 episodes: 27.57\n",
      "Episode 140\tAverage score over the last 100 episodes: 27.81\n",
      "Episode 141\tAverage score over the last 100 episodes: 28.04\n",
      "Episode 142\tAverage score over the last 100 episodes: 28.27\n",
      "Episode 143\tAverage score over the last 100 episodes: 28.49\n",
      "Episode 144\tAverage score over the last 100 episodes: 28.74\n",
      "Episode 145\tAverage score over the last 100 episodes: 28.97\n",
      "Episode 146\tAverage score over the last 100 episodes: 29.18\n",
      "Episode 147\tAverage score over the last 100 episodes: 29.37\n",
      "Episode 148\tAverage score over the last 100 episodes: 29.59\n",
      "Episode 149\tAverage score over the last 100 episodes: 29.78\n",
      "Episode 150\tAverage score over the last 100 episodes: 29.98\n",
      "Episode 151\tAverage score over the last 100 episodes: 30.18\n",
      "\n",
      "Environment solved in 151 episodes!\tAverage score over the last 100 episodes: 30.18\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea8175bd30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(num_agents=num_agents,state_size=state_size, action_size=action_size,random_seed=10)\n",
    "scores = train_ddpg(agent,save_file='checkpoint')\n",
    "plot_scores(scores)\n",
    "#agent = Agent(state_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], random_seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
